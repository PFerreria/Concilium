# Application Settings
APP_NAME=Concilium AI Assistant
APP_VERSION=1.0.0
ENVIRONMENT=development
DEBUG=true

# Server Configuration
HOST=0.0.0.0
PORT=8000
RELOAD=true

# Security
SECRET_KEY=change-this-to-a-secure-random-key-in-production
API_KEY_HEADER=X-API-Key
ALLOWED_ORIGINS=["http://localhost:3000", "http://localhost:8000", "http://127.0.0.1:3000"]

# File Upload Settings
MAX_UPLOAD_SIZE_MB=100
ALLOWED_AUDIO_FORMATS=[".mp3", ".wav", ".m4a", ".ogg", ".flac"]
ALLOWED_DOCUMENT_FORMATS=[".pdf", ".docx", ".txt", ".xlsx"]

# AI Models - Llama Configuration
LLM_MODEL_NAME=meta-llama/Llama-2-7b-chat-hf
# LLM_MODEL_PATH=  # Optional: path to local model files
HF_TOKEN=your_huggingface_token_here
LLM_MAX_TOKENS=2048
LLM_TEMPERATURE=0.7
LLM_DEVICE=cuda  # Options: cuda, cpu, mps

# Whisper Configuration
WHISPER_MODEL_SIZE=base  # Options: tiny, base, small, medium, large
WHISPER_DEVICE=cuda  # Options: cuda, cpu
# WHISPER_LANGUAGE=  # Optional: specify language code (auto-detect if not set)

# Database
DATABASE_URL=sqlite+aiosqlite:///./concilium.db

# Redis (for background tasks - optional)
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Workflow Generation
DIAGRAM_FORMAT=png  # Options: png, svg, pdf

# Logging
LOG_LEVEL=INFO  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
# LOG_FILE=logs/concilium.log
